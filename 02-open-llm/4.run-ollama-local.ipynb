{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf63a4f-a741-4b4c-8d48-fce4e2c024d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62401e7d-4f5e-4d60-9b03-504b52b17f0b",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ffc664-0b9d-4911-8c35-fcc92e5cde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../01-intro/documents.json', 'r') as f_in:\n",
    "    raw_doc = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a1a99c-e82f-4d0e-9c06-aa3ece7c5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for course_dict in raw_doc:\n",
    "    course = course_dict['course']\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b83ae0-76e3-469f-b432-3ac5793c8a69",
   "metadata": {},
   "source": [
    "# Use Elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "febbd0c5-ea8b-4b94-80f2-0562304c2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aadb784-e750-486a-af00-b25641053847",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e67508-00f9-455d-99a2-5fc228acdf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d8678b-8404-47f8-9883-c7d85c6b18c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting IProgress\n",
      "  Downloading IProgress-0.4-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: six in /home/roman/.local/share/virtualenvs/llm-zoomcamp-6WKyO3I_/lib/python3.9/site-packages (from IProgress) (1.16.0)\n",
      "Downloading IProgress-0.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: IProgress\n",
      "Successfully installed IProgress-0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install IProgress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb909460-3e97-4589-8ee3-f5191f696082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc4079b-c155-4c18-9a43-5064baceaa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 948/948 [00:07<00:00, 134.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013dd2bd-3d29-4fb2-9130-fa71c0273041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3517f17-6d33-4e77-a186-6788e330851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"how do I run kafka?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5752cef-1a39-427b-8ec3-be9398d16493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Answer: To run the provided code, ensure that the 'dlt[duckdb]' package is installed. You can do this by executing the provided installation command: !pip install dlt[duckdb]. If you’re doing it locally, be sure to also have duckdb pip installed (even before the duckdb package is loaded).\",\n",
       "  'section': 'Workshop 1 - dlthub',\n",
       "  'question': 'How do I install the necessary dependencies to run the code?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\\nHaving this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\\nYou will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\\nRemember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\\nThis is also a great resource: https://dangitgit.com/',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How do I use Git / GitHub for this course?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can check the version of your local spark using spark-submit --version. In the build.sh file of the Python folder, make sure that SPARK_VERSION matches your local version. Similarly, make sure the pyspark you pip installed also matches this version.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'How do I check compatibility of local and container Spark versions?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_search(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc40b7-116c-4fc0-8034-92c8c3e23fc1",
   "metadata": {},
   "source": [
    "# Use OLLAMA LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1371b13a-729b-4cac-ad42-5e9e61291c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef80c7f-9705-4180-934b-6cf90f4bf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientO = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f2837e0-ddc4-434a-aeac-2de72575e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_ollama(prompt):\n",
    "    response = clientO.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "255e0bf5-095d-49c3-aeed-c93abb9937ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Prerequisites:**\\n\\n* Java 1.6 or later\\n* Apache Kafka client library (for brokers >= 0.10.0)\\n\\n**Steps:**\\n\\n1. **Download and set up Kafka brokers:**\\n   - Download the Kafka broker binaries from the official website (kafka.apache.org).\\n   - Set the `KAFKA_BOOTSTRAP_SERVERS` system property to the addresses of your Kafka brokers.\\n   - Start the Kafka brokers according to the instructions provided with the installation package.\\n\\n2. **Create a producer object:**\\n   - Use the `KafkaProducer` interface to create a new Kafka producer.\\n   - Set the required properties, such as the broker address, topic name, and message properties.\\n\\n3. **Create a topic:**\\n   - Use the `KafkaProducer` to create a new Kafka topic.\\n   - The topic should be created with the specified number of partitions and replication factor.\\n\\n4. **Create a producer topic:**\\n   - Use the `KafkaProducer` to create a new Kafka topic.\\n   - The topic should be created with the specified number of partitions and replication factor.\\n\\n5. **Put messages to the topic:**\\n   - Use the `KafkaProducer` to put messages to the topic.\\n   - You can specify the message content, key, and other properties for each message.\\n\\n6. **Close the producer and topic objects:**\\n   - Once you are finished sending messages, close the `KafkaProducer` and `KafkaTopic` objects to release the resources.\\n\\n**Example Code:**\\n\\n```java\\n// Create a producer\\nKafkaProducer<String, String> producer = new KafkaProducer<>(\"localhost:9092\");\\n\\n// Create a topic\\nproducer.createTopic(\"my-topic\", 3, 1);\\n\\n// Create a producer topic\\nproducer.createTopic(\"my-topic-2\", 3, 1);\\n\\n// Put messages to the topic\\nproducer.send(\"Hello, world!\", \"my-topic\");\\n\\n// Close the producer and topic objects\\nproducer.close();\\n```\\n\\n**Note:**\\n\\n* The `bootstrap.servers` property in the `producer.properties` file specifies the brokers to connect to for bootstrap.\\n* The `key` and `value` properties specify the key and value data for each message, respectively.\\n* You can configure the producer with various properties, such as the message retention, partition assignment, and more.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_ollama(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508c22e-d395-47da-9188-6e6f53282782",
   "metadata": {},
   "source": [
    "# Put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "616235a0-3638-4e14-9e62-6be5aa525593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4ed8c9f-ad88-47ac-a8e8-1ad41d181016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_ollama_es(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm_ollama(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bad0b836-47c4-47be-ad55-0ae33b031bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure. Based on the context, the question is about how to install the necessary dependencies to run the code.\\n\\nThe context specifies that you should ensure that the 'dlt[duckdb]' package is installed before running the code.\\n\\nThe context also provides instructions on how to create a virtual environment and install packages in that environment.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_ollama_es(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa9664-de65-4fab-a710-bd4340e1d5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
